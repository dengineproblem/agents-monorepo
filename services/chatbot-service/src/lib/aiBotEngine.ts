/**
 * AI Bot Engine - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞
 * –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É ai_bot_configurations –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–æ—Ç–∞
 *
 * Features:
 * - Correlation ID –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ –≤—Å–µ —ç—Ç–∞–ø—ã
 * - –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ç–µ–ª–µ—Ñ–æ–Ω—ã, API –∫–ª—é—á–∏, UUID)
 * - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ª–æ–≥–æ–≤
 * - –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å checkpoints
 * - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—à–∏–±–æ–∫ —Å retry hints
 * - Rate limiting –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç —Å–ø–∞–º–∞
 * - Duplicate detection –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
 * - Retry –ª–æ–≥–∏–∫–∞ –¥–ª—è transient errors
 * - –ü–æ–¥—Å—á—ë—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ API –≤—ã–∑–æ–≤–æ–≤
 * - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
 */

// Using 'any' for FastifyInstance to avoid type conflicts with custom pino logger
type FastifyApp = any;
import { supabase } from './supabase.js';
import { redis } from './redis.js';
import OpenAI from 'openai';
import { sendWhatsAppMessage as sendMessage, sendPresence } from './evolutionApi.js';
import { createLogger } from './logger.js';
import {
  createContextLogger,
  ContextLogger,
  RequestContext,
  maskPhone,
  maskApiKey,
  maskUuid,
  truncateText,
  logDbOperation,
  logWebhookCall,
  logIncomingMessage,
  logOutgoingMessage,
  LogTag,
  // –ù–æ–≤—ã–µ —É—Ç–∏–ª–∏—Ç—ã
  withRetry,
  DEFAULT_RETRY_CONFIG,
  checkRateLimit,
  RateLimitConfig,
  logOpenAiCall,
  logOpenAiCallWithCost,
  calculateApiCost,
  validateMessage,
  isDuplicateMessage,
  logStageTransition,
  logProcessingSummary,
  ProcessingStage,
  safeJsonParse,
  LIMITS
} from './logUtils.js';
import {
  ConsultationIntegrationSettings,
  getConsultationToolDefinitions,
  getConsultationPromptAddition,
  isConsultationTool,
  handleConsultationTool
} from './consultationTools.js';
import {
  getCapiToolDefinitions,
  isCapiTool,
  handleCapiTool
} from './capiTools.js';
import {
  getLeadManagementToolDefinitions,
  isLeadManagementTool,
  handleLeadManagementTool
} from './leadManagementTools.js';
import {
  getBotControlToolDefinitions,
  isBotControlTool,
  handleBotControlTool
} from './botControlTools.js';
import {
  cancelPendingFollowUps,
  scheduleFirstFollowUp
} from './delayedFollowUps.js';

const baseLog = createLogger({ module: 'aiBotEngine' });

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';

// Debug –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è AI-–æ—Ç–≤–µ—Ç–æ–≤
export interface AIDebugInfo {
  // Timing
  totalProcessingMs: number;
  aiLatencyMs: number;
  sendLatencyMs: number;

  // Tokens & Cost
  model: string;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  costCents: number;

  // Tool Calls
  toolCalls: Array<{
    name: string;
    arguments: Record<string, any>;
    result: string;
    durationMs: number;
  }>;

  // Context
  iterations: number;
  systemPrompt?: string;
  historyMessagesCount?: number;
}

// Rate limit –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: 20 —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –º–∏–Ω—É—Ç—É –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω
const MESSAGE_RATE_LIMIT: RateLimitConfig = {
  maxTokens: 20,
  refillRate: 0.333, // ~20 –≤ –º–∏–Ω—É—Ç—É
  tokensPerRequest: 1
};

// –¢–∏–ø—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–æ—Ç–∞ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞
export interface AIBotConfig {
  id: string;
  user_account_id: string;
  name: string;
  is_active: boolean;
  system_prompt: string;
  temperature: number;
  model: string;

  // –ò—Å—Ç–æ—Ä–∏—è
  history_token_limit: number;
  history_message_limit: number | null;
  history_time_limit_hours: number | null;

  // –ë—É—Ñ–µ—Ä
  message_buffer_seconds: number;

  // –û–ø–µ—Ä–∞—Ç–æ—Ä
  operator_pause_enabled: boolean;
  operator_pause_ignore_first_message: boolean;
  operator_auto_resume_hours: number;
  operator_auto_resume_minutes: number;
  operator_pause_exceptions: string[];

  // –§—Ä–∞–∑—ã
  stop_phrases: string[];
  resume_phrases: string[];

  // –°–æ–æ–±—â–µ–Ω–∏—è
  split_messages: boolean;
  split_max_length: number;
  clean_markdown: boolean;

  // –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ
  schedule_enabled: boolean;
  schedule_hours_start: number;
  schedule_hours_end: number;
  schedule_days: number[];
  timezone: string;
  pass_current_datetime: boolean;

  // –ì–æ–ª–æ—Å/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–¥–æ–∫—É–º–µ–Ω—Ç—ã
  voice_recognition_enabled: boolean;
  voice_default_response: string;
  image_recognition_enabled: boolean;
  image_default_response: string;
  document_recognition_enabled: boolean;
  document_default_response: string;

  // –§–∞–π–ª—ã
  file_handling_mode: 'ignore' | 'respond';
  file_default_response: string;

  // –ü—Ä–æ—á–µ–µ
  start_message: string;
  error_message: string;
  custom_openai_api_key: string | null;

  // –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è–º–∏
  consultation_integration_enabled?: boolean;
  consultation_settings?: ConsultationIntegrationSettings;

  // –û—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (follow-up)
  delayed_schedule_enabled?: boolean;
  delayed_schedule_hours_start?: number;
  delayed_schedule_hours_end?: number;
  delayed_messages?: Array<{
    hours: number;
    minutes: number;
    prompt: string;
    repeatCount?: number;
    offHoursBehavior?: string;
    offHoursTime?: string;
  }>;
}

export interface LeadInfo {
  id: string;
  user_account_id: string;
  instance_name: string;
  contact_phone: string;
  contact_name?: string;
  funnel_stage: string;
  interest_level?: string;
  business_type?: string;
  assigned_to_human?: boolean;
  assigned_consultant_id?: string;
  bot_paused?: boolean;
  bot_paused_until?: string;
  messages?: any[];
}

/**
 * –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–æ—Ç–∞ –¥–ª—è –∏–Ω—Å—Ç–∞–Ω—Å–∞ WhatsApp
 */
export async function getBotConfigForInstance(
  instanceName: string,
  ctxLog?: ContextLogger
): Promise<AIBotConfig | null> {
  // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
  const log = ctxLog || createContextLogger(baseLog, { instanceName }, ['config', 'db']);

  log.info({ instance: instanceName }, '[getBotConfigForInstance] Starting bot config lookup', ['config']);

  try {
    // –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç–∞–Ω—Å —Å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º –±–æ—Ç–æ–º
    log.debug({ instance: instanceName }, '[getBotConfigForInstance] Querying whatsapp_instances', ['db']);
    const { data: instance, error: instanceError } = await supabase
      .from('whatsapp_instances')
      .select('ai_bot_id, user_account_id')
      .eq('instance_name', instanceName)
      .maybeSingle();

    if (instanceError) {
      log.error(instanceError, '[getBotConfigForInstance] DB error fetching instance', {
        instance: instanceName
      }, ['db']);
      return null;
    }

    if (!instance) {
      log.warn({ instance: instanceName }, '[getBotConfigForInstance] Instance not found in database', ['db']);
      return null;
    }

    logDbOperation(log, 'select', 'whatsapp_instances', {
      userId: maskUuid(instance.user_account_id),
      hasBotId: !!instance.ai_bot_id
    }, true);

    // –ï—Å–ª–∏ –±–æ—Ç –ø—Ä–∏–≤—è–∑–∞–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if (instance.ai_bot_id) {
      log.debug({ botId: maskUuid(instance.ai_bot_id) }, '[getBotConfigForInstance] Fetching linked bot config', ['db']);
      const { data: bot, error: botError } = await supabase
        .from('ai_bot_configurations')
        .select('*')
        .eq('id', instance.ai_bot_id)
        .eq('is_active', true)
        .maybeSingle();

      if (botError) {
        log.error(botError, '[getBotConfigForInstance] DB error fetching bot config', {
          botId: maskUuid(instance.ai_bot_id)
        }, ['db']);
        return null;
      }

      if (bot) {
        log.info({
          botId: maskUuid(bot.id),
          botName: bot.name,
          model: bot.model,
          temp: bot.temperature
        }, '[getBotConfigForInstance] Using linked bot', ['config']);
        return bot;
      } else {
        log.warn({ botId: maskUuid(instance.ai_bot_id) }, '[getBotConfigForInstance] Linked bot not found or inactive', ['config']);
      }
    }

    // –ï—Å–ª–∏ –±–æ—Ç –Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω - –∏—â–µ–º –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –±–æ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    log.debug({ userId: maskUuid(instance.user_account_id) }, '[getBotConfigForInstance] No linked bot, searching for default', ['db']);
    const { data: defaultBot, error: defaultError } = await supabase
      .from('ai_bot_configurations')
      .select('*')
      .eq('user_account_id', instance.user_account_id)
      .eq('is_active', true)
      .order('created_at', { ascending: false })
      .limit(1)
      .maybeSingle();

    if (defaultError) {
      log.error(defaultError, '[getBotConfigForInstance] DB error fetching default bot', {}, ['db']);
      return null;
    }

    if (defaultBot) {
      log.info({
        botId: maskUuid(defaultBot.id),
        botName: defaultBot.name,
        model: defaultBot.model
      }, '[getBotConfigForInstance] Using default active bot', ['config']);
      return defaultBot;
    }

    log.warn({
      instance: instanceName,
      userId: maskUuid(instance.user_account_id)
    }, '[getBotConfigForInstance] No active bot found for user', ['config']);
    return null;
  } catch (error: any) {
    log.error(error, '[getBotConfigForInstance] Unexpected error', { instance: instanceName });
    return null;
  }
}

/**
 * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –¥–æ–ª–∂–µ–Ω –ª–∏ –±–æ—Ç –æ—Ç–≤–µ—á–∞—Ç—å —Å —É—á—ë—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞
 */
export function shouldBotRespondWithConfig(
  lead: LeadInfo,
  botConfig: AIBotConfig,
  messageText?: string,
  ctxLog?: ContextLogger
): { shouldRespond: boolean; reason?: string } {
  const log = ctxLog || createContextLogger(baseLog, {
    leadId: lead.id,
    botId: botConfig.id
  }, ['processing']);

  log.info({
    leadId: maskUuid(lead.id),
    phone: maskPhone(lead.contact_phone),
    botName: botConfig.name,
    msgLen: messageText?.length || 0
  }, '[shouldBotRespondWithConfig] Checking if bot should respond');

  // 1. –ë–æ—Ç –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω
  if (!botConfig.is_active) {
    log.debug({ reason: 'bot_inactive' }, '[shouldBotRespondWithConfig] Bot is inactive');
    return { shouldRespond: false, reason: 'bot_inactive' };
  }

  // 2. –ú–µ–Ω–µ–¥–∂–µ—Ä –≤–∑—è–ª –≤ —Ä–∞–±–æ—Ç—É
  if (lead.assigned_to_human) {
    log.debug({ reason: 'assigned_to_human' }, '[shouldBotRespondWithConfig] Lead assigned to human');
    return { shouldRespond: false, reason: 'assigned_to_human' };
  }

  // 3. –ë–æ—Ç –Ω–∞ –ø–∞—É–∑–µ
  if (lead.bot_paused) {
    log.debug({ botPaused: true }, '[shouldBotRespondWithConfig] Bot is paused for this lead');
    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å resume_phrases - –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—Ä–∞–∑—É –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, —Å–Ω—è—Ç—å –ø–∞—É–∑—É
    if (messageText && botConfig.resume_phrases?.length > 0) {
      const lowerMessage = messageText.toLowerCase();
      log.debug({
        resumePhrasesCount: botConfig.resume_phrases.length,
        msgPreview: truncateText(lowerMessage, 60)
      }, '[shouldBotRespondWithConfig] Checking resume phrases');

      const shouldResume = botConfig.resume_phrases.some(phrase =>
        lowerMessage.includes(phrase.toLowerCase())
      );
      if (shouldResume) {
        log.info({ reason: 'resume_phrase_detected' }, '[shouldBotRespondWithConfig] Resume phrase detected, will unpause');
        return { shouldRespond: true, reason: 'resume_phrase_detected' };
      }
    }
    return { shouldRespond: false, reason: 'bot_paused' };
  }

  // 4. –ü–∞—É–∑–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
  if (lead.bot_paused_until) {
    const pausedUntil = new Date(lead.bot_paused_until);
    const now = new Date();
    const isPaused = pausedUntil > now;
    log.debug({
      pausedUntil: pausedUntil.toISOString(),
      isPaused
    }, '[shouldBotRespondWithConfig] Checking temporary pause');

    if (isPaused) {
      return { shouldRespond: false, reason: 'bot_paused_temporarily' };
    }
  }

  // 5. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å stop_phrases - –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–æ–ø-—Ñ—Ä–∞–∑—É, –ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –ø–∞—É–∑—É
  if (messageText && botConfig.stop_phrases?.length > 0) {
    const lowerMessage = messageText.toLowerCase();
    log.debug({
      stopPhrasesCount: botConfig.stop_phrases.length,
      msgPreview: truncateText(lowerMessage, 60)
    }, '[shouldBotRespondWithConfig] Checking stop phrases');

    const matchedPhrase = botConfig.stop_phrases.find(phrase =>
      lowerMessage.includes(phrase.toLowerCase())
    );
    if (matchedPhrase) {
      log.info({ matchedPhrase, reason: 'stop_phrase_detected' }, '[shouldBotRespondWithConfig] Stop phrase detected');
      return { shouldRespond: false, reason: 'stop_phrase_detected' };
    }
  }

  // 6. –≠—Ç–∞–ø—ã –≤–æ—Ä–æ–Ω–∫–∏ –≥–¥–µ –±–æ—Ç –º–æ–ª—á–∏—Ç
  const silentStages = ['consultation_completed', 'deal_closed', 'deal_lost'];
  if (silentStages.includes(lead.funnel_stage)) {
    log.debug({ funnelStage: lead.funnel_stage, reason: 'silent_stage' }, '[shouldBotRespondWithConfig] Lead in silent funnel stage');
    return { shouldRespond: false, reason: 'silent_stage' };
  }

  // 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
  if (botConfig.schedule_enabled) {
    log.debug({
      scheduleEnabled: true,
      hours: `${botConfig.schedule_hours_start}-${botConfig.schedule_hours_end}`,
      days: botConfig.schedule_days,
      tz: botConfig.timezone
    }, '[shouldBotRespondWithConfig] Checking schedule', ['schedule']);

    if (!isWithinSchedule(botConfig, log)) {
      log.debug({ reason: 'outside_schedule' }, '[shouldBotRespondWithConfig] Outside of schedule', ['schedule']);
      return { shouldRespond: false, reason: 'outside_schedule' };
    }
  }

  log.info({ shouldRespond: true }, '[shouldBotRespondWithConfig] Bot should respond');
  return { shouldRespond: true };
}

/**
 * –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
 */
function isWithinSchedule(config: AIBotConfig, ctxLog?: ContextLogger): boolean {
  const log = ctxLog || createContextLogger(baseLog, { botId: config.id }, ['schedule']);
  const now = new Date();
  const timezone = config.timezone || 'Asia/Yekaterinburg';

  log.debug({
    tz: timezone,
    nowUTC: now.toISOString()
  }, '[isWithinSchedule] Checking schedule', ['schedule']);

  // –ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è –≤ —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ –±–æ—Ç–∞
  const options: Intl.DateTimeFormatOptions = {
    timeZone: timezone,
    hour: 'numeric',
    weekday: 'short'
  };

  const formatter = new Intl.DateTimeFormat('ru-RU', options);
  const parts = formatter.formatToParts(now);

  const hourPart = parts.find(p => p.type === 'hour');
  const dayPart = parts.find(p => p.type === 'weekday');

  const hour = hourPart ? parseInt(hourPart.value) : now.getHours();

  // –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
  const dayMap: Record<string, number> = {
    '–ø–Ω': 1, '–≤—Ç': 2, '—Å—Ä': 3, '—á—Ç': 4, '–ø—Ç': 5, '—Å–±': 6, '–≤—Å': 7
  };
  const dayValue = dayPart ? dayMap[dayPart.value.toLowerCase()] || now.getDay() : now.getDay();
  const day = dayValue === 0 ? 7 : dayValue; // –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ = 7

  log.debug({
    localHour: hour,
    localDay: day,
    dayName: dayPart?.value,
    allowedDays: config.schedule_days,
    hours: `${config.schedule_hours_start}-${config.schedule_hours_end}`
  }, '[isWithinSchedule] Parsed local time', ['schedule']);

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–Ω—è –Ω–µ–¥–µ–ª–∏
  if (!config.schedule_days.includes(day)) {
    log.debug({ day, reason: 'day_not_allowed' }, '[isWithinSchedule] Day not in schedule', ['schedule']);
    return false;
  }

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
  if (hour < config.schedule_hours_start || hour >= config.schedule_hours_end) {
    log.debug({
      hour,
      reason: 'hour_outside'
    }, '[isWithinSchedule] Hour outside schedule', ['schedule']);
    return false;
  }

  log.debug({ hour, day, inSchedule: true }, '[isWithinSchedule] Within schedule', ['schedule']);
  return true;
}

/**
 * –°–∫–ª–µ–π–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ Redis —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
 * –°–æ—Ö—Ä–∞–Ω—è–µ—Ç correlation ID –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ processAIBotResponse
 */
export async function collectMessagesWithConfig(
  phone: string,
  instanceName: string,
  newMessage: string,
  botConfig: AIBotConfig,
  app: FastifyApp,
  ctx?: RequestContext
): Promise<void> {
  const ctxLog = createContextLogger(baseLog, ctx || { phone, instanceName }, ['redis', 'processing']);

  const bufferSeconds = botConfig.message_buffer_seconds || 7;
  const key = `pending_messages:${instanceName}:${phone}`;
  const timerId = `timer:${key}`;
  const ctxKey = `ctx:${key}`;

  ctxLog.info({
    bufferSec: bufferSeconds,
    msgLen: newMessage.length,
    msgPreview: truncateText(newMessage, 80)
  }, '[collectMessagesWithConfig] Adding message to buffer', ['redis']);

  // –î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥—å
  const listLength = await redis.rpush(key, newMessage);
  await redis.expire(key, bufferSeconds + 5);

  // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (correlation ID) –≤ Redis –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ timer callback
  if (ctx) {
    await redis.set(ctxKey, JSON.stringify(ctx), 'EX', bufferSeconds + 5);
  }

  ctxLog.debug({
    redisKey: key,
    listLen: listLength,
    expireSec: bufferSeconds + 5
  }, '[collectMessagesWithConfig] Message added to Redis list', ['redis']);

  // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–π–º–µ—Ä
  const exists = await redis.exists(timerId);

  if (!exists) {
    ctxLog.debug({
      timerId,
      bufferSec: bufferSeconds
    }, '[collectMessagesWithConfig] Creating new timer', ['redis']);

    await redis.set(timerId, '1', 'EX', bufferSeconds);

    // –ß–µ—Ä–µ–∑ N —Å–µ–∫—É–Ω–¥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    setTimeout(async () => {
      // –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ Redis
      let savedCtx: RequestContext | undefined;
      try {
        const ctxData = await redis.get(ctxKey);
        if (ctxData) {
          savedCtx = JSON.parse(ctxData);
        }
      } catch {
        // Ignore parse errors
      }

      const timerLog = createContextLogger(baseLog, savedCtx || { phone, instanceName }, ['redis', 'processing']);
      timerLog.info({}, '[collectMessagesWithConfig] Timer fired, processing buffered messages', ['redis']);

      try {
        const messages = await redis.lrange(key, 0, -1);
        await redis.del(key, timerId, ctxKey);

        timerLog.debug({
          msgCount: messages.length,
          msgPreviews: messages.map(m => truncateText(m, 40))
        }, '[collectMessagesWithConfig] Retrieved messages from buffer', ['redis']);

        if (messages.length > 0) {
          const combined = messages.join('\n');
          timerLog.info({
            combinedLen: combined.length,
            msgCount: messages.length
          }, '[collectMessagesWithConfig] Sending combined message to processAIBotResponse');

          await processAIBotResponse(phone, instanceName, combined, botConfig, app, savedCtx);
        } else {
          timerLog.warn({ redisKey: key }, '[collectMessagesWithConfig] No messages in buffer after timer', ['redis']);
        }
      } catch (error: any) {
        timerLog.error(error, '[collectMessagesWithConfig] Error processing collected messages', {
          phone: maskPhone(phone)
        });
      }
    }, bufferSeconds * 1000);
  } else {
    ctxLog.debug({
      timerId,
      action: 'added_to_existing'
    }, '[collectMessagesWithConfig] Timer already exists, message added to existing buffer', ['redis']);
  }
}

/**
 * –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞ –±–æ—Ç–∞
 * –ü—Ä–∏–Ω–∏–º–∞–µ—Ç RequestContext –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è correlation ID –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏
 */
async function processAIBotResponse(
  phone: string,
  instanceName: string,
  messageText: string,
  botConfig: AIBotConfig,
  app: FastifyApp,
  ctx?: RequestContext
): Promise<void> {
  const ctxLog = createContextLogger(baseLog, {
    ...ctx,
    phone,
    instanceName,
    botId: botConfig.id,
    botName: botConfig.name
  }, ['processing', 'openai']);

  ctxLog.info({
    msgLen: messageText.length,
    msgPreview: truncateText(messageText, 120)
  }, '[processAIBotResponse] Starting to process message');

  try {
    // –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏–¥–µ
    ctxLog.checkpoint('fetch_lead');
    ctxLog.debug({ phone: maskPhone(phone) }, '[processAIBotResponse] Fetching lead from database', ['db']);

    const { data: lead, error: leadError } = await supabase
      .from('dialog_analysis')
      .select('*')
      .eq('contact_phone', phone)
      .eq('instance_name', instanceName)
      .maybeSingle();

    if (leadError) {
      ctxLog.error(leadError, '[processAIBotResponse] Error fetching lead', {
        phone: maskPhone(phone)
      }, ['db']);
      return;
    }

    if (!lead) {
      ctxLog.warn({ phone: maskPhone(phone) }, '[processAIBotResponse] Lead not found', ['db']);
      return;
    }

    ctxLog.updateContext({ leadId: lead.id });
    logDbOperation(ctxLog, 'select', 'dialog_analysis', {
      leadId: maskUuid(lead.id),
      funnelStage: lead.funnel_stage
    }, true);

    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å–ª–æ–≤–∏—è –æ—Ç–≤–µ—Ç–∞
    ctxLog.checkpoint('check_respond');
    const { shouldRespond, reason } = shouldBotRespondWithConfig(lead, botConfig, messageText, ctxLog);
    if (!shouldRespond) {
      // –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç–æ–ø-—Ñ—Ä–∞–∑–∞, –ø–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ—Ç–∞ –Ω–∞ –ø–∞—É–∑—É
      if (reason === 'stop_phrase_detected') {
        ctxLog.info({ action: 'pause_bot' }, '[processAIBotResponse] Pausing bot due to stop phrase', ['db']);
        await supabase
          .from('dialog_analysis')
          .update({ bot_paused: true })
          .eq('id', lead.id);
      }
      ctxLog.info({
        reason,
        ...ctxLog.getTimings()
      }, '[processAIBotResponse] Bot should not respond, exiting');
      return;
    }

    // –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, —Å–Ω—è—Ç—å –ø–∞—É–∑—É
    if (reason === 'resume_phrase_detected') {
      ctxLog.info({ action: 'resume_bot' }, '[processAIBotResponse] Resuming bot due to resume phrase', ['db']);
      await supabase
        .from('dialog_analysis')
        .update({ bot_paused: false, bot_paused_until: null })
        .eq('id', lead.id);
    }

    // –°–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç OpenAI (—Å–≤–æ–π –∫–ª—é—á –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π)
    const apiKey = botConfig.custom_openai_api_key || OPENAI_API_KEY;
    if (!apiKey) {
      ctxLog.error(new Error('No API key'), '[processAIBotResponse] No OpenAI API key configured', {}, ['config']);
      return;
    }

    ctxLog.debug({
      hasCustomKey: !!botConfig.custom_openai_api_key,
      model: botConfig.model,
      temp: botConfig.temperature,
      apiKeyMasked: maskApiKey(apiKey)
    }, '[processAIBotResponse] Initializing OpenAI client', ['openai']);

    const openai = new OpenAI({ apiKey });

    // –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç
    ctxLog.checkpoint('generate_ai');
    ctxLog.info({}, '[processAIBotResponse] Calling generateAIResponse', ['openai']);

    const aiStartTime = Date.now();
    const response = await generateAIResponse(lead, messageText, botConfig, openai, ctxLog);
    const aiElapsed = Date.now() - aiStartTime;

    logOpenAiCall(ctxLog, {
      model: botConfig.model,
      latencyMs: aiElapsed,
      success: !!response.text
    });

    ctxLog.info({
      hasText: !!response.text,
      textLen: response.text?.length || 0,
      hasFunc: !!response.functionCall,
      moveToStage: response.moveToStage,
      needsHuman: response.needsHuman
    }, '[processAIBotResponse] AI response generated', ['openai']);

    if (!response.text) {
      ctxLog.warn({}, '[processAIBotResponse] No response text generated', ['openai']);
      return;
    }

    // –û—á–∏—Å—Ç–∏—Ç—å markdown –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    let finalText = response.text;
    if (botConfig.clean_markdown) {
      const beforeLen = finalText.length;
      finalText = cleanMarkdown(finalText);
      ctxLog.debug({
        beforeLen,
        afterLen: finalText.length,
        removed: beforeLen - finalText.length
      }, '[processAIBotResponse] Markdown cleaned');
    }

    // –†–∞–∑–±–∏—Ç—å –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    let chunks: string[];
    if (botConfig.split_messages) {
      chunks = splitMessage(finalText, botConfig.split_max_length);
      ctxLog.debug({
        splitEnabled: true,
        maxLen: botConfig.split_max_length,
        chunksCount: chunks.length
      }, '[processAIBotResponse] Message split into chunks');
    } else {
      chunks = [finalText];
    }

    // –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
    ctxLog.checkpoint('send_message');
    ctxLog.info({
      chunksCount: chunks.length,
      totalLen: finalText.length
    }, '[processAIBotResponse] Sending messages via Evolution API', ['message']);

    const sendStartTime = Date.now();
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];

      // –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç..." –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ)
      if (i > 0) {
        // –ü–æ–∫–∞–∑–∞—Ç—å "–ø–µ—á–∞—Ç–∞–µ—Ç..." –Ω–∞ 1.5-2.5 —Å–µ–∫—É–Ω–¥—ã
        const typingDelay = 1500 + Math.floor(Math.random() * 1000);

        ctxLog.info({
          chunkIdx: i + 1,
          totalChunks: chunks.length,
          typingDelay
        }, '[processAIBotResponse] Sending typing presence before chunk', ['message']);

        const presenceResult = await sendPresence(instanceName, phone, 'composing', typingDelay);

        ctxLog.info({
          presenceResult,
          typingDelay
        }, '[processAIBotResponse] Presence sent, waiting before sending message');

        await delay(typingDelay);
      }

      ctxLog.debug({
        chunkIdx: i + 1,
        totalChunks: chunks.length,
        chunkLen: chunk.length
      }, '[processAIBotResponse] Sending chunk', ['message']);

      await sendMessage({
        instanceName,
        phone,
        message: chunk
      });

      // –ü–∞—É–∑–∞ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
      if (chunks.length > 1 && i < chunks.length - 1) {
        await delay(300);
      }
    }

    const sendLatencyMs = Date.now() - sendStartTime;
    logOutgoingMessage(ctxLog, {
      messageLength: finalText.length,
      chunksCount: chunks.length,
      latencyMs: sendLatencyMs,
      success: true
    });

    // –û–±–Ω–æ–≤–∏—Ç—å debug info —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–± –æ—Ç–ø—Ä–∞–≤–∫–µ
    if (response.debug) {
      response.debug.sendLatencyMs = sendLatencyMs;
    }

    // === –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é ===
    ctxLog.checkpoint('save_history');
    ctxLog.debug({}, '[processAIBotResponse] Saving messages to history', ['db']);

    try {
      // –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∏—Å—Ç–æ—Ä–∏—é –∏ —Å—á—ë—Ç—á–∏–∫–∏
      const { data: currentLead } = await supabase
        .from('dialog_analysis')
        .select('messages, incoming_count, outgoing_count')
        .eq('id', lead.id)
        .single();

      const currentMessages = Array.isArray(currentLead?.messages) ? currentLead.messages : [];
      const currentIncoming = currentLead?.incoming_count || 0;
      const currentOutgoing = currentLead?.outgoing_count || 0;
      const now = new Date().toISOString();

      // –î–æ–±–∞–≤–∏—Ç—å –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
      currentMessages.push({
        sender: 'user',
        content: messageText,
        timestamp: now
      });

      // –î–æ–±–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ (—Å debug info –µ—Å–ª–∏ –µ—Å—Ç—å)
      const botMessage: { sender: string; content: string; timestamp: string; debug?: AIDebugInfo } = {
        sender: 'bot',
        content: finalText,
        timestamp: now
      };
      if (response.debug) {
        botMessage.debug = response.debug;
      }
      currentMessages.push(botMessage);

      // –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å–æ–æ–±—â–µ–Ω–∏–π)
      const trimmedMessages = currentMessages.slice(-LIMITS.MAX_HISTORY_MESSAGES);

      // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—á—ë—Ç—á–∏–∫–∏
      const { error: historyError } = await supabase
        .from('dialog_analysis')
        .update({
          messages: trimmedMessages,
          incoming_count: currentIncoming + 1,  // +1 –∑–∞ –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
          outgoing_count: currentOutgoing + 1   // +1 –∑–∞ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
        })
        .eq('id', lead.id);

      if (historyError) {
        ctxLog.warn({
          errorCode: historyError.code
        }, '[processAIBotResponse] Failed to save message history (non-fatal)', ['db']);
      } else {
        ctxLog.debug({
          totalMessages: trimmedMessages.length,
          addedMessages: 2
        }, '[processAIBotResponse] Message history saved', ['db']);
      }
    } catch (histError) {
      ctxLog.warn({
        error: (histError as any)?.message
      }, '[processAIBotResponse] Error saving history (non-fatal)', ['db']);
    }

    // –û–±–Ω–æ–≤–∏—Ç—å —ç—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if (response.moveToStage) {
      ctxLog.info({
        oldStage: lead.funnel_stage,
        newStage: response.moveToStage
      }, '[processAIBotResponse] Moving lead to new funnel stage', ['db']);

      await supabase
        .from('dialog_analysis')
        .update({ funnel_stage: response.moveToStage })
        .eq('id', lead.id);
    }

    // –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –º–µ–Ω–µ–¥–∂–µ—Ä
    if (response.needsHuman) {
      ctxLog.info({ action: 'transfer_human' }, '[processAIBotResponse] Transferring lead to human', ['db']);

      await supabase
        .from('dialog_analysis')
        .update({ assigned_to_human: true, bot_paused: true })
        .eq('id', lead.id);
    }

    // –í—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
    if (response.functionCall) {
      ctxLog.info({
        funcName: response.functionCall.name
      }, '[processAIBotResponse] Executing function call');

      await handleFunctionCall(response.functionCall, lead, botConfig, app, ctxLog);
    }

    // –û–±–Ω–æ–≤–∏—Ç—å –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    await supabase
      .from('dialog_analysis')
      .update({ last_bot_message_at: new Date().toISOString() })
      .eq('id', lead.id);

    ctxLog.info({
      responseLen: finalText.length,
      chunksCount: chunks.length,
      historyUpdated: true,
      ...ctxLog.getTimings()
    }, '[processAIBotResponse] Bot response sent successfully');

    // === –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ follow-up –µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞ ===
    try {
      const scheduled = await scheduleFirstFollowUp(
        {
          id: botConfig.id,
          is_active: botConfig.is_active,
          delayed_schedule_enabled: botConfig.delayed_schedule_enabled,
          delayed_schedule_hours_start: botConfig.delayed_schedule_hours_start,
          delayed_schedule_hours_end: botConfig.delayed_schedule_hours_end,
          delayed_messages: botConfig.delayed_messages || [],
          timezone: botConfig.timezone
        },
        lead.id,
        instanceName,
        phone
      );
      if (scheduled) {
        ctxLog.info({ leadId: maskUuid(lead.id) }, '[processAIBotResponse] Follow-up scheduled');
      }
    } catch (e) {
      ctxLog.warn({ error: (e as any)?.message }, '[processAIBotResponse] Failed to schedule follow-up (non-fatal)');
    }

  } catch (error: any) {
    ctxLog.error(error, '[processAIBotResponse] Error processing message', {
      phone: maskPhone(phone),
      ...ctxLog.getTimings()
    });

    // –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
    if (botConfig.error_message) {
      ctxLog.debug({
        errorMsgLen: botConfig.error_message.length
      }, '[processAIBotResponse] Sending error message to user');

      try {
        await sendMessage({
          instanceName,
          phone,
          message: botConfig.error_message
        });
      } catch (e) {
        ctxLog.error(e, '[processAIBotResponse] Failed to send error message');
      }
    }
  }
}

/**
 * –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
 * –°–æ–æ–±—â–µ–Ω–∏—è —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ JSONB –ø–æ–ª–µ 'messages' —Ç–∞–±–ª–∏—Ü—ã dialog_analysis
 */
async function loadMessageHistory(
  leadId: string,
  config: AIBotConfig,
  ctxLog?: ContextLogger
): Promise<OpenAI.Chat.Completions.ChatCompletionMessageParam[]> {
  const log = ctxLog || createContextLogger(baseLog, { leadId }, ['db']);

  log.debug({
    tokenLimit: config.history_token_limit,
    msgLimit: config.history_message_limit,
    timeLimitH: config.history_time_limit_hours
  }, '[loadMessageHistory] Starting to load message history', ['db']);

  try {
    // –ü–æ–ª—É—á–∏—Ç—å messages –∏–∑ dialog_analysis
    const { data: lead, error } = await supabase
      .from('dialog_analysis')
      .select('messages')
      .eq('id', leadId)
      .single();

    if (error) {
      log.warn({
        errorCode: error.code
      }, '[loadMessageHistory] Error fetching messages from database', ['db']);
      return [];
    }

    if (!lead?.messages) {
      log.debug({}, '[loadMessageHistory] No message history found in database', ['db']);
      return [];
    }

    // messages - —ç—Ç–æ JSONB –º–∞—Å—Å–∏–≤ [{sender, content, timestamp}, ...]
    const rawMessages = Array.isArray(lead.messages) ? lead.messages : [];
    log.debug({
      rawCount: rawMessages.length
    }, '[loadMessageHistory] Raw messages loaded from JSONB', ['db']);

    // –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ
    const now = new Date();
    let filteredMessages = rawMessages;

    if (config.history_time_limit_hours) {
      const cutoff = new Date(now.getTime() - config.history_time_limit_hours * 60 * 60 * 1000);
      const beforeCount = filteredMessages.length;
      filteredMessages = rawMessages.filter((msg: any) => {
        const msgTime = new Date(msg.timestamp || msg.created_at || 0);
        return msgTime >= cutoff;
      });
      log.debug({
        timeLimitH: config.history_time_limit_hours,
        beforeCount,
        afterCount: filteredMessages.length
      }, '[loadMessageHistory] Applied time filter');
    }

    // –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π (–±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N)
    if (config.history_message_limit && filteredMessages.length > config.history_message_limit) {
      const beforeCount = filteredMessages.length;
      filteredMessages = filteredMessages.slice(-config.history_message_limit);
      log.debug({
        msgLimit: config.history_message_limit,
        beforeCount,
        afterCount: filteredMessages.length
      }, '[loadMessageHistory] Applied message limit');
    }

    // –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI —Å —É—á—ë—Ç–æ–º —Ç–æ–∫–µ–Ω-–ª–∏–º–∏—Ç–∞
    let totalTokens = 0;
    const tokenLimit = config.history_token_limit || 10000;

    // –ò–¥—ë–º —Å –∫–æ–Ω—Ü–∞ (–Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤–∞–∂–Ω–µ–µ) –∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–∫–∞ –Ω–µ –ø—Ä–µ–≤—ã—Å–∏–º –ª–∏–º–∏—Ç
    const reversedMessages = [...filteredMessages].reverse();
    const history: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [];
    let skippedDueToTokens = 0;

    for (const msg of reversedMessages) {
      const content = msg.content || msg.text || '';
      const estimatedTokens = Math.ceil(content.length / 4);

      if (totalTokens + estimatedTokens > tokenLimit) {
        skippedDueToTokens++;
        continue;
      }

      // –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–æ–ª—å: bot/assistant = assistant, –æ—Å—Ç–∞–ª—å–Ω–æ–µ = user
      const sender = (msg.sender || msg.from || 'user').toLowerCase();
      const role = (sender === 'bot' || sender === 'assistant') ? 'assistant' : 'user';

      history.unshift({
        role,
        content
      });

      totalTokens += estimatedTokens;
    }

    log.info({
      rawCount: rawMessages.length,
      filteredCount: filteredMessages.length,
      finalCount: history.length,
      estTokens: totalTokens,
      tokenLimit,
      skipped: skippedDueToTokens
    }, '[loadMessageHistory] Message history loaded successfully');

    return history;
  } catch (error: any) {
    log.error(error, '[loadMessageHistory] Unexpected error loading message history');
    return [];
  }
}

/**
 * –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI
 */
async function generateAIResponse(
  lead: LeadInfo,
  messageText: string,
  config: AIBotConfig,
  openai: OpenAI,
  ctxLog?: ContextLogger
): Promise<{
  text: string;
  moveToStage?: string;
  needsHuman?: boolean;
  functionCall?: { name: string; arguments: any };
  debug?: AIDebugInfo;
}> {
  const log = ctxLog || createContextLogger(baseLog, {
    leadId: lead.id,
    botId: config.id
  }, ['openai']);

  const generateStartTime = Date.now();

  log.checkpoint('start_generate');
  log.info({
    model: config.model,
    temp: config.temperature,
    msgLen: messageText.length
  }, '[generateAIResponse] Starting AI response generation', ['openai']);

  // –ü–æ–ª—É—á–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –±–æ—Ç–∞
  log.debug({}, '[generateAIResponse] Fetching bot functions', ['db']);
  const { data: functions, error: functionsError } = await supabase
    .from('ai_bot_functions')
    .select('*')
    .eq('bot_id', config.id)
    .eq('is_active', true);

  if (functionsError) {
    log.warn({
      errorCode: functionsError.code
    }, '[generateAIResponse] Error fetching bot functions', ['db']);
  }

  log.debug({
    funcCount: functions?.length || 0,
    funcNames: functions?.map(f => f.name) || []
  }, '[generateAIResponse] Bot functions loaded', ['db']);

  // –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
  let systemPrompt = config.system_prompt || '–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.';
  log.debug({
    promptLen: systemPrompt.length
  }, '[generateAIResponse] Base system prompt');

  // –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É/–≤—Ä–µ–º—è –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
  if (config.pass_current_datetime) {
    const now = new Date();
    const formatter = new Intl.DateTimeFormat('ru-RU', {
      timeZone: config.timezone,
      weekday: 'long',
      year: 'numeric',
      month: 'long',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    });
    const formattedDate = formatter.format(now);
    systemPrompt += `\n\n–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: ${formattedDate}`;
    log.debug({ datetime: formattedDate }, '[generateAIResponse] Added datetime to prompt');
  }

  // –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–µ
  // AI —Å–∞–º —Ä–µ—à–∞–µ—Ç - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–º—è –∏–∑ WhatsApp –∏–ª–∏ —Å–ø—Ä–æ—Å–∏—Ç—å –∫–ª–∏–µ–Ω—Ç–∞
  const whatsappName = lead.contact_name?.trim() || null;

  const clientInfo = `
–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∏–µ–Ω—Ç–µ:
- –ò–º—è –∏–∑ WhatsApp: ${whatsappName || '–ù–ï –£–ö–ê–ó–ê–ù–û'}
- –¢–µ–ª–µ—Ñ–æ–Ω: ${lead.contact_phone}
- –¢–∏–ø –±–∏–∑–Ω–µ—Å–∞: ${lead.business_type || '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
- –£—Ä–æ–≤–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–∞: ${lead.interest_level || '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
- –≠—Ç–∞–ø –≤–æ—Ä–æ–Ω–∫–∏: ${lead.funnel_stage}

–ü–†–ê–í–ò–õ–ê —Ä–∞–±–æ—Ç—ã —Å –∏–º–µ–Ω–µ–º –∫–ª–∏–µ–Ω—Ç–∞:
1. –ü–æ—Å–º–æ—Ç—Ä–∏ "–ò–º—è –∏–∑ WhatsApp" –≤—ã—à–µ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ ‚Äî —ç—Ç–æ –Ω–∞—Å—Ç–æ—è—â–µ–µ –∏–º—è –∏–ª–∏ –º—É—Å–æ—Ä

   ‚úÖ –ù–ê–°–¢–û–Ø–©–ï–ï –ò–ú–Ø (–∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ–±—Ä–∞—â–µ–Ω–∏—è):
   –ê–ª–µ–∫—Å–∞–Ω–¥—Ä, –ú–∞—Ä–∏—è, –î–º–∏—Ç—Ä–∏–π, –ê–Ω–Ω–∞, –û–ª–µ–≥, –ï–∫–∞—Ç–µ—Ä–∏–Ω–∞, John, Anna, Mike
   –°–∞—à–∞, –ú–∞—à–∞, –ö–∞—Ç—è, –õ—ë—à–∞ (—Å–æ–∫—Ä–∞—â—ë–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ —Ç–æ–∂–µ –û–ö)

   ‚ùå –ú–£–°–û–† (–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π, —Å–ø—Ä–æ—Å–∏ –∫–∞–∫ –æ–±—Ä–∞—â–∞—Ç—å—Å—è):
   - –≠–º–æ–¥–∑–∏: üî•, üí™, ‚ù§Ô∏è, –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã
   - –¶–∏—Ñ—Ä—ã/–Ω–æ–º–µ—Ä–∞: 123, +7999, 89001234567
   - –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ: user, client, guest, test, undefined
   - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è: –ø—Ä–∏–≤–µ—Ç, hi, hello, oi
   - –ë–∏–∑–Ω–µ—Å-–Ω–∞–∑–≤–∞–Ω–∏—è: "–°–∞–ª–æ–Ω –∫—Ä–∞—Å–æ—Ç—ã", "–ú–∞–≥–∞–∑–∏–Ω", "–ò–ü –ò–≤–∞–Ω–æ–≤", "Company"
   - –§—Ä–∞–∑—ã: "–º–µ–Ω—è –ª–µ–≥–∫–æ –Ω–∞–π—Ç–∏", "–ø–æ–∑–≤–æ–Ω–∏ –º–Ω–µ", "whatsapp business"
   - –ù–∏–∫–Ω–µ–π–º—ã: @username, cool_guy_2000

2. –ï—Å–ª–∏ –∏–º—è –Ω–∞—Å—Ç–æ—è—â–µ–µ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ —Å—Ä–∞–∑—É, –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –∑–∞–Ω–æ–≤–æ
3. –ï—Å–ª–∏ –º—É—Å–æ—Ä/–Ω–µ —É–∫–∞–∑–∞–Ω–æ ‚Üí –ø—Ä–∏ —É–¥–æ–±–Ω–æ–º –º–æ–º–µ–Ω—Ç–µ —Å–ø—Ä–æ—Å–∏ "–ö–∞–∫ —è –º–æ–≥—É –∫ –≤–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è?"
4. –ö–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –Ω–∞–∑–æ–≤—ë—Ç –∏–º—è ‚Üí –°–†–ê–ó–£ —Å–æ—Ö—Ä–∞–Ω–∏ —á–µ—Ä–µ–∑ update_lead_info(contact_name: "–ò–º—è")
5. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π "—É–≤–∞–∂–∞–µ–º—ã–π –∫–ª–∏–µ–Ω—Ç" ‚Äî –ª—É—á—à–µ –æ–±—â–∞–π—Å—è –±–µ–∑ –∏–º–µ–Ω–∏ –¥–æ —É—Ç–æ—á–Ω–µ–Ω–∏—è`;

  log.debug({
    whatsappName,
    businessType: lead.business_type,
    funnelStage: lead.funnel_stage
  }, '[generateAIResponse] Client info added to prompt');

  // –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –µ—Å–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞
  if (config.consultation_integration_enabled && config.consultation_settings) {
    // –î–æ–±–∞–≤–∏—Ç—å user_account_id –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
    const settingsWithUserId = {
      ...config.consultation_settings,
      user_account_id: config.consultation_settings.user_account_id || config.user_account_id
    };

    const consultationPrompt = await getConsultationPromptAddition(
      settingsWithUserId,
      undefined,
      lead.assigned_consultant_id
    );
    systemPrompt += consultationPrompt;
    log.debug({
      consultationEnabled: true,
      hasAssignedConsultant: !!lead.assigned_consultant_id
    }, '[generateAIResponse] Added consultation integration prompt');
  }

  // –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å tools –¥–ª—è OpenAI
  const tools: OpenAI.Chat.Completions.ChatCompletionTool[] = [];

  if (functions && functions.length > 0) {
    for (const func of functions) {
      tools.push({
        type: 'function',
        function: {
          name: func.name,
          description: func.description,
          parameters: func.parameters || { type: 'object', properties: {} }
        }
      });
    }
    log.debug({
      toolsCount: tools.length,
      toolNames: tools.map(t => t.function.name)
    }, '[generateAIResponse] Prepared OpenAI tools', ['openai']);
  }

  // –î–æ–±–∞–≤–∏—Ç—å consultation tools –µ—Å–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞
  if (config.consultation_integration_enabled && config.consultation_settings) {
    // –î–æ–±–∞–≤–∏—Ç—å user_account_id –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
    const settingsWithUserId = {
      ...config.consultation_settings,
      user_account_id: config.consultation_settings.user_account_id || config.user_account_id
    };

    const consultationTools = getConsultationToolDefinitions(settingsWithUserId);
    tools.push(...consultationTools);
    log.debug({
      consultationToolsCount: consultationTools.length,
      consultationToolNames: consultationTools.map(t => t.function.name)
    }, '[generateAIResponse] Added consultation tools', ['openai']);
  }

  // –î–æ–±–∞–≤–∏—Ç—å CAPI tools (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã)
  const capiTools = getCapiToolDefinitions();
  tools.push(...capiTools);
  log.debug({
    capiToolsCount: capiTools.length,
    capiToolNames: capiTools.map(t => t.function.name)
  }, '[generateAIResponse] Added CAPI tools', ['openai']);

  // –î–æ–±–∞–≤–∏—Ç—å Lead Management tools (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã)
  const leadManagementTools = getLeadManagementToolDefinitions();
  tools.push(...leadManagementTools);
  log.debug({
    leadToolsCount: leadManagementTools.length,
    leadToolNames: leadManagementTools.map(t => t.function.name)
  }, '[generateAIResponse] Added Lead Management tools', ['openai']);

  // –î–æ–±–∞–≤–∏—Ç—å Bot Control tools (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã)
  const botControlTools = getBotControlToolDefinitions();
  tools.push(...botControlTools);
  log.debug({
    botControlToolsCount: botControlTools.length,
    botControlToolNames: botControlTools.map(t => t.function.name)
  }, '[generateAIResponse] Added Bot Control tools', ['openai']);

  // –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
  const model = config.model || 'gpt-4o-mini';
  log.debug({ model }, '[generateAIResponse] Using model', ['openai']);

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è debug info (–¥–æ try –±–ª–æ–∫–∞ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –≤ catch)
  const debugInfo: AIDebugInfo = {
    model,
    promptTokens: 0,
    completionTokens: 0,
    totalTokens: 0,
    costCents: 0,
    aiLatencyMs: 0,
    toolCalls: [],
    iterations: 0,
    systemPrompt: systemPrompt + clientInfo,
    historyMessagesCount: 0, // –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
    totalProcessingMs: 0,
    sendLatencyMs: 0
  };

  try {
    // –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    log.checkpoint('load_history');
    const history = await loadMessageHistory(lead.id, config, log);

    // –û–±–Ω–æ–≤–ª—è–µ–º debug info –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
    debugInfo.historyMessagesCount = history.length;

    // –°–æ–±—Ä–∞—Ç—å –º–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π: system + history + —Ç–µ–∫—É—â–µ–µ
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt + clientInfo },
      ...history,
      { role: 'user', content: messageText }
    ];

    log.debug({
      totalMsgs: messages.length,
      historyLen: history.length,
      userMsgLen: messageText.length
    }, '[generateAIResponse] Messages array prepared', ['openai']);

    // GPT-5 –º–æ–¥–µ–ª–∏ (reasoning) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç temperature –∏ max_tokens
    const isGpt5Model = model.startsWith('gpt-5') || model.startsWith('o3') || model.startsWith('o4');

    const completionParams: OpenAI.Chat.Completions.ChatCompletionCreateParamsNonStreaming = {
      model,
      messages,
      ...(isGpt5Model
        ? { max_completion_tokens: 10000 }  // GPT-5: –±–µ–∑ temperature, –∏—Å–ø–æ–ª—å–∑—É–µ–º max_completion_tokens
        : { temperature: config.temperature, max_tokens: 1000 }  // GPT-4: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
      )
    };

    if (tools.length > 0) {
      completionParams.tools = tools;
      completionParams.tool_choice = 'auto';
    }

    log.checkpoint('api_call');
    log.info({
      model,
      isGpt5Model,
      ...(isGpt5Model
        ? { maxCompletionTokens: 4096 }
        : { temp: config.temperature, maxTokens: 1000 }
      ),
      msgsCount: messages.length,
      toolsCount: tools.length
    }, '[generateAIResponse] Calling OpenAI API', ['openai', 'api']);

    const apiStartTime = Date.now();
    let completion = await openai.chat.completions.create(completionParams);
    let apiElapsed = Date.now() - apiStartTime;

    let choice = completion.choices[0];

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–æ–≥ —Å –ø–æ–¥—Å—á—ë—Ç–æ–º —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    logOpenAiCallWithCost(log, {
      model,
      promptTokens: completion.usage?.prompt_tokens,
      completionTokens: completion.usage?.completion_tokens,
      totalTokens: completion.usage?.total_tokens,
      latencyMs: apiElapsed,
      success: true
    });

    // –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º debug –¥–∞–Ω–Ω—ã–µ
    debugInfo.promptTokens += completion.usage?.prompt_tokens || 0;
    debugInfo.completionTokens += completion.usage?.completion_tokens || 0;
    debugInfo.totalTokens += completion.usage?.total_tokens || 0;
    debugInfo.aiLatencyMs += apiElapsed;

    log.info({
      finishReason: choice.finish_reason,
      hasContent: !!choice.message.content,
      contentLen: choice.message.content?.length || 0,
      hasToolCalls: !!choice.message.tool_calls?.length,
      promptTokens: completion.usage?.prompt_tokens,
      completionTokens: completion.usage?.completion_tokens
    }, '[generateAIResponse] OpenAI API response received', ['openai']);

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ tool_calls –≤ —Ü–∏–∫–ª–µ (–¥–æ 3 –∏—Ç–µ—Ä–∞—Ü–∏–π)
    const toolCallsExecuted: string[] = [];
    let iterations = 0;
    const maxIterations = 3;

    while (choice.message.tool_calls && choice.message.tool_calls.length > 0 && iterations < maxIterations) {
      iterations++;
      log.info({
        iteration: iterations,
        toolCallsCount: choice.message.tool_calls.length,
        toolNames: choice.message.tool_calls.map(tc => tc.function.name)
      }, '[generateAIResponse] Processing tool calls');

      // –î–æ–±–∞–≤–∏—Ç—å assistant message —Å tool_calls
      messages.push({
        role: 'assistant',
        content: choice.message.content || null,
        tool_calls: choice.message.tool_calls
      } as OpenAI.Chat.Completions.ChatCompletionMessageParam);

      // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—ã–π tool call
      for (const toolCall of choice.message.tool_calls) {
        const functionName = toolCall.function.name;
        const args = safeJsonParse<Record<string, any>>(
          toolCall.function.arguments || '{}',
          {},
          log,
          `function_call:${functionName}`
        );
        toolCallsExecuted.push(functionName);

        log.info({
          functionName,
          args
        }, '[generateAIResponse] Executing tool call');

        let toolResult = '';
        const toolStartTime = Date.now();

        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å consultation tools
        if (isConsultationTool(functionName) && config.consultation_settings) {
          const leadInfo = {
            id: lead.id,
            contact_phone: lead.contact_phone,
            contact_name: lead.contact_name,
            assigned_consultant_id: lead.assigned_consultant_id ?? undefined
          };

          log.debug({
            leadId: maskUuid(lead.id),
            hasAssignedConsultant: !!lead.assigned_consultant_id,
            assignedConsultantId: lead.assigned_consultant_id ? maskUuid(lead.assigned_consultant_id) : null,
            functionName
          }, '[generateAIResponse] Processing consultation tool with lead assignment', ['consultation']);

          // –î–æ–±–∞–≤–∏—Ç—å user_account_id –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
          const settingsWithUserId = {
            ...config.consultation_settings,
            user_account_id: config.consultation_settings.user_account_id || config.user_account_id
          };

          toolResult = await handleConsultationTool(
            functionName,
            args,
            leadInfo,
            settingsWithUserId,
            log
          );
        }
        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å CAPI tools
        else if (isCapiTool(functionName)) {
          toolResult = await handleCapiTool(
            functionName,
            args,
            lead.id,
            log
          );
        }
        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å Lead Management tools
        else if (isLeadManagementTool(functionName)) {
          toolResult = await handleLeadManagementTool(
            functionName,
            args,
            {
              id: lead.id,
              contact_phone: lead.contact_phone,
              contact_name: lead.contact_name,
              funnel_stage: lead.funnel_stage,
              interest_level: lead.interest_level
            },
            log
          );
        }
        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å Bot Control tools
        else if (isBotControlTool(functionName)) {
          toolResult = await handleBotControlTool(
            functionName,
            args,
            { id: lead.id },
            log
          );
        }
        // –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        else {
          toolResult = `[–§—É–Ω–∫—Ü–∏—è ${functionName} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞]`;
          log.warn({ functionName }, '[generateAIResponse] Unknown function called');
        }

        const toolDuration = Date.now() - toolStartTime;

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ debug info
        debugInfo.toolCalls.push({
          name: functionName,
          arguments: args,
          result: toolResult,
          durationMs: toolDuration
        });

        log.info({
          functionName,
          resultLen: toolResult.length
        }, '[generateAIResponse] Tool call completed');

        // –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ tool message
        messages.push({
          role: 'tool',
          tool_call_id: toolCall.id,
          content: toolResult
        } as OpenAI.Chat.Completions.ChatCompletionMessageParam);
      }

      // –°–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ tool calls
      log.info({
        iteration: iterations,
        msgsCount: messages.length
      }, '[generateAIResponse] Calling OpenAI with tool results');

      const followUpStartTime = Date.now();
      const followUpParams: OpenAI.Chat.Completions.ChatCompletionCreateParamsNonStreaming = {
        model,
        messages,
        ...(isGpt5Model
          ? { max_completion_tokens: 10000 }
          : { temperature: config.temperature, max_tokens: 1000 }
        ),
        tools: tools.length > 0 ? tools : undefined,
        tool_choice: tools.length > 0 ? 'auto' : undefined
      };
      completion = await openai.chat.completions.create(followUpParams);
      apiElapsed = Date.now() - followUpStartTime;

      choice = completion.choices[0];

      logOpenAiCallWithCost(log, {
        model,
        promptTokens: completion.usage?.prompt_tokens,
        completionTokens: completion.usage?.completion_tokens,
        totalTokens: completion.usage?.total_tokens,
        latencyMs: apiElapsed,
        success: true
      });

      // –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º debug –¥–∞–Ω–Ω—ã–µ (follow-up –≤—ã–∑–æ–≤—ã)
      debugInfo.promptTokens += completion.usage?.prompt_tokens || 0;
      debugInfo.completionTokens += completion.usage?.completion_tokens || 0;
      debugInfo.totalTokens += completion.usage?.total_tokens || 0;
      debugInfo.aiLatencyMs += apiElapsed;
      debugInfo.iterations = iterations;

      log.info({
        iteration: iterations,
        finishReason: choice.finish_reason,
        hasContent: !!choice.message.content,
        hasToolCalls: !!choice.message.tool_calls?.length
      }, '[generateAIResponse] Follow-up response received');
    }

    // –ï—Å–ª–∏ –ø–æ—Å–ª–µ tool calls –ø–æ–ª—É—á–∏–ª–∏ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç, –¥–µ–ª–∞–µ–º –µ—â—ë –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –±–µ–∑ tools
    if (!choice.message.content && toolCallsExecuted.length > 0) {
      log.warn({
        toolCallsExecuted,
        finishReason: choice.finish_reason
      }, '[generateAIResponse] Empty response after tool calls, retrying without tools');

      const retryStartTime = Date.now();
      const retryParams: OpenAI.Chat.Completions.ChatCompletionCreateParamsNonStreaming = {
        model,
        messages,
        ...(isGpt5Model
          ? { max_completion_tokens: 10000 }
          : { temperature: config.temperature, max_tokens: 1000 }
        )
        // –ë–µ–∑ tools - –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
      };
      const retryCompletion = await openai.chat.completions.create(retryParams);
      const retryElapsed = Date.now() - retryStartTime;

      choice = retryCompletion.choices[0];

      // –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º debug –¥–∞–Ω–Ω—ã–µ (retry –≤—ã–∑–æ–≤)
      debugInfo.promptTokens += retryCompletion.usage?.prompt_tokens || 0;
      debugInfo.completionTokens += retryCompletion.usage?.completion_tokens || 0;
      debugInfo.totalTokens += retryCompletion.usage?.total_tokens || 0;
      debugInfo.aiLatencyMs += retryElapsed;

      log.info({
        retryResponseLen: choice.message.content?.length || 0
      }, '[generateAIResponse] Retry response received');
    }

    if (toolCallsExecuted.length > 0) {
      log.info({
        toolCallsExecuted,
        iterations,
        finalResponseLen: choice.message.content?.length || 0
      }, '[generateAIResponse] Completed with tool calls executed');
    }

    // –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è debug info
    debugInfo.totalProcessingMs = Date.now() - generateStartTime;
    const costResult = calculateApiCost(model, debugInfo.promptTokens, debugInfo.completionTokens);
    debugInfo.costCents = costResult.totalCostCents;

    log.info({
      responseLen: choice.message.content?.length || 0,
      responsePreview: truncateText(choice.message.content || '', 100),
      ...log.getTimings()
    }, '[generateAIResponse] Completed with text response', ['openai']);

    return {
      text: choice.message.content || '',
      debug: debugInfo
    };

  } catch (error: any) {
    logOpenAiCallWithCost(log, {
      model,
      latencyMs: 0,
      success: false,
      errorMessage: error.message
    });

    log.error(error, '[generateAIResponse] Error calling OpenAI', {
      model,
      errorCode: error.code,
      errorStatus: error.status,
      ...log.getTimings()
    }, ['openai', 'api']);

    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º partial debug –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    debugInfo.totalProcessingMs = Date.now() - generateStartTime;
    const costResult = calculateApiCost(model, debugInfo.promptTokens, debugInfo.completionTokens);
    debugInfo.costCents = costResult.totalCostCents;

    return { text: '', debug: debugInfo };
  }
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –±–æ—Ç–∞
 */
async function handleFunctionCall(
  functionCall: { name: string; arguments: any },
  lead: LeadInfo,
  botConfig: AIBotConfig,
  app: FastifyApp,
  ctxLog?: ContextLogger
): Promise<void> {
  const log = ctxLog || createContextLogger(baseLog, {
    leadId: lead.id,
    botId: botConfig.id
  }, ['processing']);

  log.checkpoint('start_function');
  log.info({
    funcName: functionCall.name,
    argsKeys: Object.keys(functionCall.arguments || {})
  }, '[handleFunctionCall] Starting function execution');

  try {
    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ CAPI tool
    if (isCapiTool(functionCall.name)) {
      log.info({
        funcName: functionCall.name
      }, '[handleFunctionCall] Processing CAPI tool', ['api']);

      const result = await handleCapiTool(
        functionCall.name,
        functionCall.arguments,
        lead.id,
        log
      );

      log.info({
        funcName: functionCall.name,
        resultLen: result.length,
        ...log.getTimings()
      }, '[handleFunctionCall] CAPI tool completed', ['api']);

      return;
    }

    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ Lead Management tool
    if (isLeadManagementTool(functionCall.name)) {
      log.info({
        funcName: functionCall.name
      }, '[handleFunctionCall] Processing Lead Management tool', ['processing']);

      const result = await handleLeadManagementTool(
        functionCall.name,
        functionCall.arguments,
        {
          id: lead.id,
          contact_phone: lead.contact_phone,
          contact_name: lead.contact_name,
          funnel_stage: lead.funnel_stage,
          interest_level: lead.interest_level
        },
        log
      );

      log.info({
        funcName: functionCall.name,
        resultLen: result.length,
        ...log.getTimings()
      }, '[handleFunctionCall] Lead Management tool completed', ['processing']);

      return;
    }

    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ Bot Control tool
    if (isBotControlTool(functionCall.name)) {
      log.info({
        funcName: functionCall.name
      }, '[handleFunctionCall] Processing Bot Control tool', ['processing']);

      const result = await handleBotControlTool(
        functionCall.name,
        functionCall.arguments,
        {
          id: lead.id,
          contact_phone: lead.contact_phone,
          contact_name: lead.contact_name,
          messages: lead.messages,
          funnel_stage: lead.funnel_stage,
          interest_level: lead.interest_level
        },
        log
      );

      log.info({
        funcName: functionCall.name,
        resultLen: result.length,
        ...log.getTimings()
      }, '[handleFunctionCall] Bot Control tool completed', ['processing']);

      return;
    }

    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ consultation tool
    if (isConsultationTool(functionCall.name)) {
      if (!botConfig.consultation_integration_enabled || !botConfig.consultation_settings) {
        log.warn({
          funcName: functionCall.name
        }, '[handleFunctionCall] Consultation tool called but integration is disabled');
        return;
      }

      const leadInfo = {
        id: lead.id,
        contact_phone: lead.contact_phone,
        contact_name: lead.contact_name,
        assigned_consultant_id: lead.assigned_consultant_id ?? undefined
      };

      log.info({
        funcName: functionCall.name,
        hasAssignedConsultant: !!lead.assigned_consultant_id,
        assignedConsultantId: lead.assigned_consultant_id ? maskUuid(lead.assigned_consultant_id) : null
      }, '[handleFunctionCall] Processing consultation tool with lead assignment', ['consultation']);

      const result = await handleConsultationTool(
        functionCall.name,
        functionCall.arguments,
        leadInfo,
        botConfig.consultation_settings,
        log
      );

      log.info({
        funcName: functionCall.name,
        resultLen: result.length,
        ...log.getTimings()
      }, '[handleFunctionCall] Consultation tool completed', ['consultation']);

      // –†–µ–∑—É–ª—å—Ç–∞—Ç consultation tool —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞
      // AI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç—Ç–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É
      return;
    }

    // –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–∏
    log.debug({
      funcName: functionCall.name
    }, '[handleFunctionCall] Fetching function config from database', ['db']);

    const { data: func, error: funcError } = await supabase
      .from('ai_bot_functions')
      .select('*')
      .eq('bot_id', botConfig.id)
      .eq('name', functionCall.name)
      .eq('is_active', true)
      .maybeSingle();

    if (funcError) {
      log.error(funcError, '[handleFunctionCall] Error fetching function config', {
        funcName: functionCall.name
      }, ['db']);
      return;
    }

    if (!func) {
      log.warn({
        funcName: functionCall.name
      }, '[handleFunctionCall] Function not found or inactive', ['db']);
      return;
    }

    logDbOperation(log, 'select', 'ai_bot_functions', {
      funcId: maskUuid(func.id),
      handlerType: func.handler_type
    }, true);

    switch (func.handler_type) {
      case 'forward_to_manager':
        log.info({
          phone: maskPhone(lead.contact_phone),
          action: 'forward_to_manager'
        }, '[handleFunctionCall] Forwarding lead to manager', ['db']);

        const { error: forwardError } = await supabase
          .from('dialog_analysis')
          .update({ assigned_to_human: true, bot_paused: true })
          .eq('id', lead.id);

        if (forwardError) {
          log.error(forwardError, '[handleFunctionCall] Error updating lead for manager forward', {}, ['db']);
        } else {
          logDbOperation(log, 'update', 'dialog_analysis', { action: 'forward_to_manager' }, true);
          log.info({ ...log.getTimings() }, '[handleFunctionCall] Successfully forwarded to manager');
        }
        break;

      case 'internal':
        log.debug({
          funcName: functionCall.name,
          argsKeys: Object.keys(functionCall.arguments || {})
        }, '[handleFunctionCall] Processing internal function');

        // –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        if (functionCall.name === 'save_user_data') {
          log.info({
            fieldsToSave: Object.keys(functionCall.arguments || {})
          }, '[handleFunctionCall] Saving user data', ['db']);

          const { error: saveError } = await supabase
            .from('dialog_analysis')
            .update(functionCall.arguments)
            .eq('id', lead.id);

          if (saveError) {
            log.error(saveError, '[handleFunctionCall] Error saving user data', {}, ['db']);
          } else {
            logDbOperation(log, 'update', 'dialog_analysis', {
              savedFields: Object.keys(functionCall.arguments || {})
            }, true);
            log.info({ ...log.getTimings() }, '[handleFunctionCall] User data saved successfully');
          }
        } else {
          log.warn({
            funcName: functionCall.name
          }, '[handleFunctionCall] Unknown internal function');
        }
        break;

      case 'webhook':
        // –í—ã–∑–æ–≤ –≤–Ω–µ—à–Ω–µ–≥–æ webhook
        if (func.handler_config?.url) {
          const webhookUrl = func.handler_config.url;
          const webhookPayload = {
            function: functionCall.name,
            arguments: functionCall.arguments,
            lead: {
              id: lead.id,
              phone: lead.contact_phone,
              name: lead.contact_name
            }
          };

          log.info({
            payloadSize: JSON.stringify(webhookPayload).length
          }, '[handleFunctionCall] Calling external webhook', ['webhook', 'api']);

          try {
            const webhookStartTime = Date.now();
            const response = await fetch(webhookUrl, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(webhookPayload)
            });

            const webhookElapsed = Date.now() - webhookStartTime;

            logWebhookCall(log, {
              url: webhookUrl,
              method: 'POST',
              statusCode: response.status,
              latencyMs: webhookElapsed,
              success: response.ok
            });

            log.info({ ...log.getTimings() }, '[handleFunctionCall] Webhook called successfully', ['webhook']);
          } catch (e) {
            logWebhookCall(log, {
              url: webhookUrl,
              method: 'POST',
              latencyMs: 0,
              success: false,
              errorMessage: (e as any).message
            });
            log.error(e, '[handleFunctionCall] Webhook call failed', {}, ['webhook', 'api']);
          }
        } else {
          log.warn({
            funcName: functionCall.name,
            reason: 'no_url'
          }, '[handleFunctionCall] Webhook URL not configured', ['webhook']);
        }
        break;

      default:
        log.warn({
          handlerType: func.handler_type,
          funcName: functionCall.name
        }, '[handleFunctionCall] Unknown handler type');
    }

    log.info({
      funcName: functionCall.name,
      handlerType: func.handler_type,
      ...log.getTimings()
    }, '[handleFunctionCall] Function execution completed');

  } catch (error: any) {
    log.error(error, '[handleFunctionCall] Unexpected error handling function call', {
      funcName: functionCall.name,
      ...log.getTimings()
    });
  }
}

/**
 * –û—á–∏—Å—Ç–∫–∞ markdown —Ä–∞–∑–º–µ—Ç–∫–∏
 */
function cleanMarkdown(text: string): string {
  return text
    .replace(/\*\*/g, '')
    .replace(/\*/g, '')
    .replace(/_/g, '')
    .replace(/`/g, '')
    .replace(/#{1,6}\s/g, '')
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1');
}

/**
 * –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏
 */
function splitMessage(text: string, maxLength: number = 500): string[] {
  if (text.length <= maxLength) return [text];

  const sentences = text.split(/(?<=[.!?])\s+/);
  const chunks: string[] = [];
  let current = '';

  for (const sentence of sentences) {
    if ((current + ' ' + sentence).length > maxLength) {
      if (current) chunks.push(current.trim());
      current = sentence;
    } else {
      current += (current ? ' ' : '') + sentence;
    }
  }

  if (current) chunks.push(current.trim());
  return chunks;
}

/**
 * –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∑–∞–¥–µ—Ä–∂–∫–∏
 */
function delay(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ—Ç–∞ - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ WhatsApp
 * –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è UI —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ –±–æ—Ç–æ–≤
 * –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞: –±—É—Ñ–µ—Ä, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ, —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π, consultation tools
 */
export async function testBotResponse(
  botId: string,
  messageText: string,
  conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }> = []
): Promise<{
  success: boolean;
  response?: string;
  responses?: string[]; // –î–ª—è split_messages - –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π
  error?: string;
  bufferApplied?: number; // –°–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –±—É—Ñ–µ—Ä–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ
  scheduleBlocked?: boolean; // –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º
  toolCalls?: string[]; // –ö–∞–∫–∏–µ tools –±—ã–ª–∏ –≤—ã–∑–≤–∞–Ω—ã
}> {
  const ctxLog = createContextLogger(baseLog, { botId }, ['processing', 'openai']);

  ctxLog.info({
    msgLen: messageText.length,
    historyLen: conversationHistory.length
  }, '[testBotResponse] Starting test bot response');

  try {
    // –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–æ—Ç–∞ –Ω–∞–ø—Ä—è–º—É—é –ø–æ ID
    const { data: botConfig, error: botError } = await supabase
      .from('ai_bot_configurations')
      .select('*')
      .eq('id', botId)
      .single();

    if (botError || !botConfig) {
      ctxLog.warn({ botId }, '[testBotResponse] Bot not found');
      return { success: false, error: 'Bot not found' };
    }

    ctxLog.info({
      botName: botConfig.name,
      model: botConfig.model,
      temp: botConfig.temperature,
      bufferSec: botConfig.message_buffer_seconds,
      scheduleEnabled: botConfig.schedule_enabled,
      splitMessages: botConfig.split_messages,
      consultationEnabled: botConfig.consultation_integration_enabled
    }, '[testBotResponse] Bot config loaded');

    // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
    if (botConfig.schedule_enabled) {
      const now = new Date();
      const timezone = botConfig.timezone || 'Asia/Yekaterinburg';

      // –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Ç–∞–π–º–∑–æ–Ω–µ –±–æ—Ç–∞
      const formatter = new Intl.DateTimeFormat('en-US', {
        timeZone: timezone,
        hour: 'numeric',
        hour12: false,
        weekday: 'short'
      });
      const parts = formatter.formatToParts(now);
      const currentHour = parseInt(parts.find(p => p.type === 'hour')?.value || '0');
      const dayName = parts.find(p => p.type === 'weekday')?.value || '';

      // –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –≤ —á–∏—Å–ª–æ (1=–ü–Ω, 7=–í—Å)
      const dayMap: Record<string, number> = { 'Mon': 1, 'Tue': 2, 'Wed': 3, 'Thu': 4, 'Fri': 5, 'Sat': 6, 'Sun': 7 };
      const currentDay = dayMap[dayName] || 1;

      const scheduleDays = botConfig.schedule_days || [1, 2, 3, 4, 5, 6, 7];
      const startHour = botConfig.schedule_hours_start ?? 9;
      const endHour = botConfig.schedule_hours_end ?? 21;

      const isDayAllowed = scheduleDays.includes(currentDay);
      const isHourAllowed = currentHour >= startHour && currentHour < endHour;

      if (!isDayAllowed || !isHourAllowed) {
        ctxLog.info({
          currentDay,
          currentHour,
          scheduleDays,
          startHour,
          endHour
        }, '[testBotResponse] Schedule blocked');

        return {
          success: true,
          response: `[–ë–æ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é. –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: ${currentHour}:00, –¥–µ–Ω—å: ${currentDay}. –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ: ${startHour}:00-${endHour}:00, –¥–Ω–∏: ${scheduleDays.join(', ')}]`,
          scheduleBlocked: true
        };
      }
    }

    // –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±—É—Ñ–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π (—ç–º—É–ª—è—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏)
    const bufferSeconds = botConfig.message_buffer_seconds || 0;
    if (bufferSeconds > 0) {
      ctxLog.info({ bufferSeconds }, '[testBotResponse] Applying message buffer delay');
      await delay(bufferSeconds * 1000);
    }

    // –°–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç OpenAI
    const apiKey = botConfig.custom_openai_api_key || OPENAI_API_KEY;
    if (!apiKey) {
      return { success: false, error: 'No OpenAI API key configured' };
    }

    const openai = new OpenAI({ apiKey });

    // –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    let systemPrompt = botConfig.system_prompt || '–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.';

    // –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É/–≤—Ä–µ–º—è –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
    if (botConfig.pass_current_datetime) {
      const now = new Date();
      const formatter = new Intl.DateTimeFormat('ru-RU', {
        timeZone: botConfig.timezone || 'Asia/Yekaterinburg',
        weekday: 'long',
        year: 'numeric',
        month: 'long',
        day: 'numeric',
        hour: '2-digit',
        minute: '2-digit'
      });
      systemPrompt += `\n\n–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: ${formatter.format(now)}`;
    }

    // –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–µ
    systemPrompt += `\n\n–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º. –¢–µ–ª–µ—Ñ–æ–Ω –∫–ª–∏–µ–Ω—Ç–∞: +7 999 000 0000 (—Ç–µ—Å—Ç).`;

    // –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å tools
    const tools: OpenAI.Chat.Completions.ChatCompletionTool[] = [];

    // –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å consultation settings –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
    let consultationSettings: ConsultationIntegrationSettings | null = null;
    if (botConfig.consultation_integration_enabled && botConfig.consultation_settings) {
      // consultation_settings —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ snake_case –≤ –ë–î
      const dbSettings = botConfig.consultation_settings;
      consultationSettings = {
        consultant_ids: dbSettings.consultant_ids || [],
        slots_to_show: dbSettings.slots_to_show || 5,
        default_duration_minutes: dbSettings.default_duration_minutes || 60,
        days_ahead_limit: dbSettings.days_ahead_limit || 14,
        auto_summarize_dialog: dbSettings.auto_summarize_dialog ?? true,
        collect_client_name: dbSettings.collect_client_name ?? true,
        timezone: botConfig.timezone || 'Asia/Yekaterinburg',
        user_account_id: botConfig.user_account_id
      };

      // –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
      const consultationPrompt = await getConsultationPromptAddition(consultationSettings, undefined, undefined);
      systemPrompt += consultationPrompt;

      // –î–æ–±–∞–≤–∏—Ç—å tools –¥–ª—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
      const consultationTools = getConsultationToolDefinitions(consultationSettings);
      tools.push(...consultationTools);

      ctxLog.info({
        consultationToolsCount: consultationTools.length,
        slotsToShow: consultationSettings.slots_to_show,
        daysAhead: consultationSettings.days_ahead_limit
      }, '[testBotResponse] Added consultation tools');
    }

    // –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–æ–±—â–µ–Ω–∏–π
    let limitedHistory = [...conversationHistory];
    if (botConfig.history_message_limit && limitedHistory.length > botConfig.history_message_limit) {
      limitedHistory = limitedHistory.slice(-botConfig.history_message_limit);
      ctxLog.debug({
        originalLen: conversationHistory.length,
        limitedLen: limitedHistory.length,
        limit: botConfig.history_message_limit
      }, '[testBotResponse] History limited by message count');
    }

    // –ú–∞–ø–ø–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π
    const modelMap: Record<string, string> = {
      'gpt-5.2': 'gpt-4o',
      'gpt-5.1': 'gpt-4o',
      'gpt-5': 'gpt-4o',
      'gpt-5-mini': 'gpt-4o-mini',
      'gpt-5-nano': 'gpt-4o-mini',
      'gpt-4.1': 'gpt-4o',
      'gpt-4.1-mini': 'gpt-4o-mini',
      'gpt-4.1-nano': 'gpt-4o-mini',
      'gpt-4o': 'gpt-4o',
      'gpt-4o-mini': 'gpt-4o-mini',
      'gpt-o3': 'gpt-4o'
    };

    const model = modelMap[botConfig.model] || 'gpt-4o-mini';

    // –°–æ–±—Ä–∞—Ç—å –º–∞—Å—Å–∏–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      ...limitedHistory.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      })),
      { role: 'user', content: messageText }
    ];

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    const completionParams: OpenAI.Chat.Completions.ChatCompletionCreateParamsNonStreaming = {
      model,
      messages,
      temperature: botConfig.temperature,
      max_tokens: 1000
    };

    // –î–æ–±–∞–≤–∏—Ç—å tools –µ—Å–ª–∏ –µ—Å—Ç—å
    if (tools.length > 0) {
      completionParams.tools = tools;
      completionParams.tool_choice = 'auto';
    }

    ctxLog.info({
      model,
      msgsCount: messages.length,
      temp: botConfig.temperature,
      toolsCount: tools.length
    }, '[testBotResponse] Calling OpenAI');

    let completion = await openai.chat.completions.create(completionParams);
    let choice = completion.choices[0];
    const toolCallsExecuted: string[] = [];

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ tool calls (–¥–æ 3 –∏—Ç–µ—Ä–∞—Ü–∏–π)
    let iterations = 0;
    const maxIterations = 3;

    while (choice.message.tool_calls && choice.message.tool_calls.length > 0 && iterations < maxIterations) {
      iterations++;
      ctxLog.info({
        iteration: iterations,
        toolCallsCount: choice.message.tool_calls.length,
        toolNames: choice.message.tool_calls.map(tc => tc.function.name)
      }, '[testBotResponse] Processing tool calls');

      // –î–æ–±–∞–≤–∏—Ç—å assistant message —Å tool_calls
      messages.push({
        role: 'assistant',
        content: choice.message.content || null,
        tool_calls: choice.message.tool_calls
      } as OpenAI.Chat.Completions.ChatCompletionMessageParam);

      // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—ã–π tool call
      for (const toolCall of choice.message.tool_calls) {
        const functionName = toolCall.function.name;
        const args = JSON.parse(toolCall.function.arguments || '{}');
        toolCallsExecuted.push(functionName);

        ctxLog.info({
          functionName,
          args
        }, '[testBotResponse] Executing tool call');

        let toolResult = '';

        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å consultation tools
        if (isConsultationTool(functionName) && consultationSettings) {
          // –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π lead –¥–ª—è consultation tools
          const testLead = {
            id: '00000000-0000-0000-0000-000000000000', // –¢–µ—Å—Ç–æ–≤—ã–π UUID
            contact_phone: '+79990000000',
            contact_name: '–¢–µ—Å—Ç–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç',
            assigned_consultant_id: undefined  // –í —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞
          };

          toolResult = await handleConsultationTool(
            functionName,
            args,
            testLead,
            consultationSettings,
            ctxLog
          );
        } else {
          toolResult = `[–§—É–Ω–∫—Ü–∏—è ${functionName} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ]`;
        }

        ctxLog.info({
          functionName,
          resultLen: toolResult.length
        }, '[testBotResponse] Tool call completed');

        // –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ tool message
        messages.push({
          role: 'tool',
          tool_call_id: toolCall.id,
          content: toolResult
        } as OpenAI.Chat.Completions.ChatCompletionMessageParam);
      }

      // –°–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ tool calls
      ctxLog.info({
        iteration: iterations,
        msgsCount: messages.length
      }, '[testBotResponse] Calling OpenAI with tool results');

      completion = await openai.chat.completions.create({
        model,
        messages,
        temperature: botConfig.temperature,
        max_tokens: 1000,
        tools: tools.length > 0 ? tools : undefined,
        tool_choice: tools.length > 0 ? 'auto' : undefined
      });

      choice = completion.choices[0];
    }

    let responseText = choice.message?.content || '';

    // –ï—Å–ª–∏ –ø–æ—Å–ª–µ tool calls –ø–æ–ª—É—á–∏–ª–∏ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç, –¥–µ–ª–∞–µ–º –µ—â—ë –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –±–µ–∑ tools
    if (!responseText && toolCallsExecuted.length > 0) {
      ctxLog.warn({
        toolCallsExecuted,
        finishReason: choice.finish_reason,
        hasToolCalls: !!choice.message?.tool_calls?.length
      }, '[testBotResponse] Empty response after tool calls, retrying without tools');

      const retryCompletion = await openai.chat.completions.create({
        model,
        messages,
        temperature: botConfig.temperature,
        max_tokens: 1000
        // –ë–µ–∑ tools - –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
      });

      responseText = retryCompletion.choices[0]?.message?.content || '';
      ctxLog.info({
        retryResponseLen: responseText.length
      }, '[testBotResponse] Retry response received');
    }

    // –û—á–∏—Å—Ç–∏—Ç—å markdown –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if (botConfig.clean_markdown) {
      responseText = responseText
        .replace(/\*\*/g, '')
        .replace(/\*/g, '')
        .replace(/_/g, '')
        .replace(/`/g, '')
        .replace(/#{1,6}\s/g, '')
        .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1');
    }

    // –†–∞–∑–±–∏—Ç—å –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ split_messages
    let responses: string[] = [responseText];
    const splitEnabled = botConfig.split_messages === true;
    const maxLength = botConfig.split_max_length || 500;

    ctxLog.info({
      splitEnabled,
      maxLength,
      responseLen: responseText.length,
      shouldSplit: splitEnabled && responseText.length > maxLength,
      toolCallsCount: toolCallsExecuted.length
    }, '[testBotResponse] Split check');

    if (splitEnabled && responseText.length > maxLength) {
      responses = splitMessage(responseText, maxLength);
      ctxLog.info({
        originalLen: responseText.length,
        chunksCount: responses.length,
        maxLen: maxLength
      }, '[testBotResponse] Response split into chunks');
    }

    ctxLog.info({
      responseLen: responseText.length,
      tokens: completion.usage?.total_tokens,
      chunksCount: responses.length,
      bufferApplied: bufferSeconds,
      toolCalls: toolCallsExecuted
    }, '[testBotResponse] Response generated');

    return {
      success: true,
      response: responses.join('\n\n---\n\n'), // –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –¥–ª—è UI
      responses, // –ú–∞—Å—Å–∏–≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
      bufferApplied: bufferSeconds,
      toolCalls: toolCallsExecuted.length > 0 ? toolCallsExecuted : undefined
    };

  } catch (error: any) {
    ctxLog.error(error, '[testBotResponse] Error generating test response');
    return {
      success: false,
      error: error.message || 'Unknown error'
    };
  }
}

/**
 * –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
 * –°–æ–∑–¥–∞—ë—Ç correlation ID –¥–ª—è –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
 *
 * –í–∫–ª—é—á–∞–µ—Ç:
 * - Rate limiting –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç —Å–ø–∞–º–∞
 * - Duplicate detection –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
 * - –í–∞–ª–∏–¥–∞—Ü–∏—é –∏ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
 * - –ü–æ–ª–Ω—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É —á–µ—Ä–µ–∑ –≤—Å–µ —ç—Ç–∞–ø—ã
 */
export async function processIncomingMessage(
  phone: string,
  instanceName: string,
  messageText: string,
  messageType: 'text' | 'image' | 'audio' | 'document' | 'file',
  app: FastifyApp
): Promise<{ processed: boolean; reason?: string; correlationId?: string }> {
  // –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ª–æ–≥–≥–µ—Ä —Å correlation ID
  const ctxLog = createContextLogger(baseLog, {
    phone,
    instanceName
  }, ['message', 'processing']);

  let currentStage: ProcessingStage = 'received';

  ctxLog.info({
    msgType: messageType,
    msgLength: messageText?.length || 0,
    msgPreview: truncateText(messageText, 80)
  }, '[processIncomingMessage] === NEW INCOMING MESSAGE ===');

  // –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
  logIncomingMessage(ctxLog, {
    messageType,
    messageLength: messageText?.length || 0,
    hasMedia: ['image', 'audio', 'document', 'file'].includes(messageType)
  });

  try {
    // === –≠–¢–ê–ü 1: Rate Limiting ===
    const rateLimitKey = `msg:${instanceName}:${phone}`;
    const rateCheck = checkRateLimit(rateLimitKey, MESSAGE_RATE_LIMIT, ctxLog);

    if (!rateCheck.allowed) {
      ctxLog.warn({
        reason: 'rate_limited',
        retryAfterMs: rateCheck.retryAfterMs,
        remainingTokens: rateCheck.remainingTokens
      }, '[processIncomingMessage] Rate limit exceeded, dropping message', ['validation']);

      logProcessingSummary(ctxLog, {
        success: false,
        finalStage: 'received',
        errorMessage: 'Rate limit exceeded',
        isExpected: true
      });

      return { processed: false, reason: 'rate_limited', correlationId: ctxLog.context.correlationId };
    }

    // === –≠–¢–ê–ü 2: Duplicate Detection ===
    if (messageText && isDuplicateMessage(phone, instanceName, messageText, ctxLog)) {
      logProcessingSummary(ctxLog, {
        success: false,
        finalStage: 'received',
        errorMessage: 'Duplicate message',
        isExpected: true
      });

      return { processed: false, reason: 'duplicate_message', correlationId: ctxLog.context.correlationId };
    }

    // === –≠–¢–ê–ü 3: Validation ===
    logStageTransition(ctxLog, currentStage, 'validated');
    currentStage = 'validated';

    const validation = validateMessage(messageText, ctxLog);
    if (!validation.valid) {
      ctxLog.warn({
        warnings: validation.warnings,
        reason: 'invalid_message'
      }, '[processIncomingMessage] Message validation failed', ['validation']);

      logProcessingSummary(ctxLog, {
        success: false,
        finalStage: 'validated',
        errorMessage: 'Invalid message'
      });

      return { processed: false, reason: 'invalid_message', correlationId: ctxLog.context.correlationId };
    }

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    const sanitizedText = validation.sanitized;
    if (validation.warnings.length > 0) {
      ctxLog.debug({
        warnings: validation.warnings,
        originalLen: messageText?.length,
        sanitizedLen: sanitizedText.length
      }, '[processIncomingMessage] Message sanitized with warnings', ['validation']);
    }

    // === –≠–¢–ê–ü 4: –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–æ—Ç–∞ ===
    logStageTransition(ctxLog, currentStage, 'config_loaded');
    currentStage = 'config_loaded';

    ctxLog.debug({ instance: instanceName }, '[processIncomingMessage] Fetching bot configuration', ['config']);

    const botConfig = await withRetry(
      () => getBotConfigForInstance(instanceName, ctxLog),
      ctxLog,
      'getBotConfigForInstance',
      { ...DEFAULT_RETRY_CONFIG, maxRetries: 2 }
    ).catch(() => null);

    if (!botConfig) {
      ctxLog.warn({
        reason: 'no_bot_config',
        ...ctxLog.getTimings()
      }, '[processIncomingMessage] No bot config found, message will not be processed', ['config']);

      logProcessingSummary(ctxLog, {
        success: false,
        finalStage: currentStage,
        errorMessage: 'No bot config found'
      });

      return { processed: false, reason: 'no_bot_config', correlationId: ctxLog.context.correlationId };
    }

    // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –±–æ—Ç–∞
    ctxLog.updateContext({
      botId: botConfig.id,
      botName: botConfig.name,
      userAccountId: botConfig.user_account_id
    });

    ctxLog.info({
      botId: maskUuid(botConfig.id),
      botName: botConfig.name,
      model: botConfig.model,
      isActive: botConfig.is_active,
      bufferSec: botConfig.message_buffer_seconds,
      scheduleEnabled: botConfig.schedule_enabled
    }, '[processIncomingMessage] Bot config loaded', ['config']);

    // === –≠–¢–ê–ü 5: –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏–¥–µ ===
    logStageTransition(ctxLog, currentStage, 'lead_loaded');
    currentStage = 'lead_loaded';

    ctxLog.debug({ phone: maskPhone(phone) }, '[processIncomingMessage] Fetching lead info', ['db']);

    let { data: lead, error: leadError } = await supabase
      .from('dialog_analysis')
      .select('*')
      .eq('contact_phone', phone)
      .eq('instance_name', instanceName)
      .maybeSingle();

    if (leadError) {
      ctxLog.error(leadError, '[processIncomingMessage] Error fetching lead', {
        phone: maskPhone(phone),
        instance: instanceName
      }, ['db']);

      logProcessingSummary(ctxLog, {
        success: false,
        finalStage: currentStage,
        errorMessage: 'Lead fetch error'
      });

      return { processed: false, reason: 'lead_fetch_error', correlationId: ctxLog.context.correlationId };
    }

    // –ï—Å–ª–∏ –ª–∏–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω - —Å–æ–∑–¥–∞—ë–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    if (!lead) {
      ctxLog.info({
        phone: maskPhone(phone),
        instance: instanceName
      }, '[processIncomingMessage] Lead not found, creating new one', ['db']);

      const now = new Date().toISOString();
      const { data: newLead, error: createError } = await supabase
        .from('dialog_analysis')
        .insert({
          user_account_id: botConfig.user_account_id,
          instance_name: instanceName,
          contact_phone: phone,
          first_message: now,
          last_message: now,
          funnel_stage: 'new_lead',
          analyzed_at: now
        })
        .select()
        .single();

      if (createError || !newLead) {
        ctxLog.error(createError, '[processIncomingMessage] Failed to create lead', {
          phone: maskPhone(phone),
          instance: instanceName
        }, ['db']);

        logProcessingSummary(ctxLog, {
          success: false,
          finalStage: currentStage,
          errorMessage: 'Failed to create lead'
        });

        return { processed: false, reason: 'lead_create_error', correlationId: ctxLog.context.correlationId };
      }

      lead = newLead;
      ctxLog.info({ leadId: maskUuid(newLead.id) }, '[processIncomingMessage] New lead created', ['db']);

      // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞ –Ω–æ–≤–æ–º—É –ª–∏–¥—É (round-robin)
      try {
        const { data: consultantId, error: assignError } = await supabase
          .rpc('assign_lead_to_consultant', {
            p_user_account_id: botConfig.user_account_id
          });

        if (!assignError && consultantId) {
          // –û–±–Ω–æ–≤–ª—è–µ–º assigned_consultant_id –≤ —Å–æ–∑–¥–∞–Ω–Ω–æ–º –ª–∏–¥–µ
          await supabase
            .from('dialog_analysis')
            .update({ assigned_consultant_id: consultantId })
            .eq('id', newLead.id);

          ctxLog.info({
            leadId: maskUuid(newLead.id),
            consultantId: maskUuid(consultantId)
          }, '[processIncomingMessage] Lead assigned to consultant (round-robin)', ['db']);

          // –û–±–Ω–æ–≤–ª—è–µ–º lead –æ–±—ä–µ–∫—Ç —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–º –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–º
          lead.assigned_consultant_id = consultantId;
        } else if (assignError) {
          ctxLog.warn({
            leadId: maskUuid(newLead.id),
            error: assignError.message
          }, '[processIncomingMessage] Failed to assign consultant (non-fatal)', ['db']);
        } else {
          ctxLog.debug({
            leadId: maskUuid(newLead.id)
          }, '[processIncomingMessage] No consultants available for assignment', ['db']);
        }
      } catch (assignErr: any) {
        ctxLog.warn({
          leadId: maskUuid(newLead.id),
          error: assignErr.message
        }, '[processIncomingMessage] Error assigning consultant (non-fatal)', ['db']);
      }
    }

    // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –ª–∏–¥–∞
    ctxLog.updateContext({ leadId: lead.id });

    logDbOperation(ctxLog, 'select', 'dialog_analysis', {
      leadId: maskUuid(lead.id),
      contactName: lead.contact_name,
      funnelStage: lead.funnel_stage,
      botPaused: lead.bot_paused,
      assignedToHuman: lead.assigned_to_human
    }, true);

    // === –û—Ç–º–µ–Ω–∞ pending follow-ups –ø—Ä–∏ –≤—Ö–æ–¥—è—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ ===
    try {
      const cancelledCount = await cancelPendingFollowUps(lead.id);
      if (cancelledCount > 0) {
        ctxLog.info({ cancelledCount, leadId: maskUuid(lead.id) }, '[processIncomingMessage] Cancelled pending follow-ups');
      }
    } catch (e) {
      ctxLog.warn({ error: (e as any)?.message }, '[processIncomingMessage] Failed to cancel follow-ups (non-fatal)');
    }

    // === –≠–¢–ê–ü 6: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å–ª–æ–≤–∏—è –æ—Ç–≤–µ—Ç–∞ ===
    logStageTransition(ctxLog, currentStage, 'conditions_checked');
    currentStage = 'conditions_checked';

    const { shouldRespond, reason } = shouldBotRespondWithConfig(lead, botConfig, sanitizedText, ctxLog);
    if (!shouldRespond) {
      ctxLog.info({
        reason,
        ...ctxLog.getTimings()
      }, '[processIncomingMessage] Bot should not respond');

      logProcessingSummary(ctxLog, {
        success: true, // –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏, –Ω–æ —Ä–µ—à–∏–ª–∏ –Ω–µ –æ—Ç–≤–µ—á–∞—Ç—å
        finalStage: currentStage
      });

      return { processed: false, reason, correlationId: ctxLog.context.correlationId };
    }

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º sanitizedText –≤–º–µ—Å—Ç–æ messageText
    let textToProcess = sanitizedText;

    ctxLog.debug({
      msgType: messageType,
      hasText: !!sanitizedText,
      textLength: sanitizedText?.length || 0
    }, '[processIncomingMessage] Processing message by type');

    switch (messageType) {
      case 'audio':
        ctxLog.debug({
          voiceEnabled: botConfig.voice_recognition_enabled
        }, '[processIncomingMessage] Processing audio message');

        if (!botConfig.voice_recognition_enabled) {
          ctxLog.info({
            hasDefault: !!botConfig.voice_default_response
          }, '[processIncomingMessage] Voice recognition disabled, sending default response');

          if (botConfig.voice_default_response) {
            await sendMessage({
              instanceName,
              phone,
              message: botConfig.voice_default_response
            });
          }
          return { processed: true, reason: 'voice_not_supported', correlationId: ctxLog.context.correlationId };
        }
        if (!messageText || messageText.trim() === '') {
          ctxLog.warn({}, '[processIncomingMessage] Empty audio message (no transcription)');
          return { processed: false, reason: 'empty_audio_message', correlationId: ctxLog.context.correlationId };
        }
        ctxLog.debug({ transcriptionLen: messageText.length }, '[processIncomingMessage] Audio has transcription');
        break;

      case 'image':
        ctxLog.debug({
          imageEnabled: botConfig.image_recognition_enabled
        }, '[processIncomingMessage] Processing image message');

        if (!botConfig.image_recognition_enabled) {
          ctxLog.info({
            hasDefault: !!botConfig.image_default_response
          }, '[processIncomingMessage] Image recognition disabled, sending default response');

          if (botConfig.image_default_response) {
            await sendMessage({
              instanceName,
              phone,
              message: botConfig.image_default_response
            });
          }
          return { processed: true, reason: 'image_not_supported', correlationId: ctxLog.context.correlationId };
        }
        if (!sanitizedText || sanitizedText.trim() === '') {
          ctxLog.warn({}, '[processIncomingMessage] Empty image message (no caption)');
          return { processed: false, reason: 'empty_image_message', correlationId: ctxLog.context.correlationId };
        }
        ctxLog.debug({ captionLen: sanitizedText.length }, '[processIncomingMessage] Image has caption');
        break;

      case 'document':
        ctxLog.debug({
          docEnabled: botConfig.document_recognition_enabled
        }, '[processIncomingMessage] Processing document message');

        if (!botConfig.document_recognition_enabled) {
          ctxLog.info({
            hasDefault: !!botConfig.document_default_response
          }, '[processIncomingMessage] Document recognition disabled, sending default response');

          if (botConfig.document_default_response) {
            await sendMessage({
              instanceName,
              phone,
              message: botConfig.document_default_response
            });
          }
          return { processed: true, reason: 'document_not_supported', correlationId: ctxLog.context.correlationId };
        }
        if (!sanitizedText || sanitizedText.trim() === '') {
          ctxLog.warn({}, '[processIncomingMessage] Empty document message (no caption)');
          return { processed: false, reason: 'empty_document_message', correlationId: ctxLog.context.correlationId };
        }
        ctxLog.debug({ captionLen: sanitizedText.length }, '[processIncomingMessage] Document has caption');
        break;

      case 'file':
        ctxLog.debug({
          fileMode: botConfig.file_handling_mode
        }, '[processIncomingMessage] Processing file message');

        if (botConfig.file_handling_mode === 'respond') {
          ctxLog.info({
            hasDefault: !!botConfig.file_default_response
          }, '[processIncomingMessage] File handling mode is respond');

          if (botConfig.file_default_response) {
            await sendMessage({
              instanceName,
              phone,
              message: botConfig.file_default_response
            });
          }
          return { processed: true, reason: 'file_responded', correlationId: ctxLog.context.correlationId };
        }
        ctxLog.info({}, '[processIncomingMessage] File ignored per config');
        return { processed: false, reason: 'file_ignored', correlationId: ctxLog.context.correlationId };

      case 'text':
      default:
        if (!sanitizedText || sanitizedText.trim() === '') {
          ctxLog.warn({ msgType: messageType }, '[processIncomingMessage] Empty text message');
          return { processed: false, reason: 'empty_message', correlationId: ctxLog.context.correlationId };
        }
        ctxLog.debug({ textLen: sanitizedText.length }, '[processIncomingMessage] Text message validated');
        break;
    }

    // === –≠–¢–ê–ü 7: –ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è ===
    logStageTransition(ctxLog, currentStage, 'buffered');
    currentStage = 'buffered';

    ctxLog.info({
      textLen: textToProcess.length,
      bufferSec: botConfig.message_buffer_seconds
    }, '[processIncomingMessage] Adding to message buffer', ['redis']);

    await collectMessagesWithConfig(phone, instanceName, textToProcess, botConfig, app, ctxLog.context);

    logProcessingSummary(ctxLog, {
      success: true,
      finalStage: currentStage
    });

    ctxLog.info({
      msgType: messageType,
      ...ctxLog.getTimings()
    }, '[processIncomingMessage] Message queued for processing successfully');

    return { processed: true, correlationId: ctxLog.context.correlationId };
  } catch (error: any) {
    ctxLog.error(error, '[processIncomingMessage] Unexpected error processing message', {
      msgType: messageType,
      ...ctxLog.getTimings()
    });

    logProcessingSummary(ctxLog, {
      success: false,
      finalStage: currentStage,
      errorMessage: error?.message
    });

    return { processed: false, reason: 'error', correlationId: ctxLog.context.correlationId };
  }
}
